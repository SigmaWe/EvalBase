{
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'P_03')": {
    "0": 0.7643570109,
    "average": 0.7643570109
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'R_03')": {
    "0": 0.5000079339,
    "average": 0.5000079339
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'F_03')": {
    "0": 0.499813154,
    "average": 0.499813154
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'P_04')": {
    "0": 0.775464633,
    "average": 0.775464633
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'R_04')": {
    "0": 0.499813154,
    "average": 0.499813154
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'F_04')": {
    "0": 0.499813154,
    "average": 0.499813154
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'P_05')": {
    "0": 0.7848668393,
    "average": 0.7848668393
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'R_05')": {
    "0": 0.499813154,
    "average": 0.499813154
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'F_05')": {
    "0": 0.499813154,
    "average": 0.499813154
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'P_06')": {
    "0": 0.7907947427,
    "average": 0.7907947427
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'R_06')": {
    "0": 0.499813154,
    "average": 0.499813154
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'F_06')": {
    "0": 0.499813154,
    "average": 0.499813154
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'P_07')": {
    "0": 0.7992908876,
    "average": 0.7992908876
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'R_07')": {
    "0": 0.5,
    "average": 0.5
  },
  "('balanced_accuracy_score', 'human', 'new', 'bertscore-sentence-mnli-deberta-entail_contradict', 'F_07')": {
    "0": 0.5,
    "average": 0.5
  }
}